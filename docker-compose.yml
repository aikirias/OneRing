x-airflow-common: &airflow-common
  image: apache/airflow:2.10.5-python3.11
  env_file:
    - .env
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "false"
    AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW_LOAD_EXAMPLES}
    AIRFLOW__CORE__DEFAULT_TIMEZONE: ${TZ}
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
    AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/0
    AIRFLOW__CELERY__FLOWER_URL_PREFIX: /
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_FERNET_KEY}
    AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.session
    AIRFLOW__LOGGING__REMOTE_LOGGING: "False"
    AIRFLOW__SECRETS__BACKEND: config.infisical_backend.InfisicalSecretsBackend
    INFISICAL_SERVER_URL: ${INFISICAL_SERVER_URL}
    INFISICAL_CLIENT_ID: ${INFISICAL_CLIENT_ID}
    INFISICAL_CLIENT_SECRET: ${INFISICAL_CLIENT_SECRET}
    INFISICAL_WORKSPACE_ID: ${INFISICAL_WORKSPACE_ID}
    INFISICAL_ENVIRONMENT: ${INFISICAL_ENVIRONMENT}
    MLFLOW_TRACKING_URI: ${MLFLOW_INTERNAL_TRACKING_URI}
    MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
    AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
    AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
    MLFLOW_MODEL_NAME: ${MLFLOW_MODEL_NAME}
    FEAST_REPO_PATH: /opt/airflow/feast_repo
    FEAST_PROJECT_NAME: ${FEAST_PROJECT_NAME}
    FEAST_REFERENCE_DATA_PATH: /opt/airflow/storage/data/ml
    BENTOML_HOME: /home/airflow/bentoml
    AIRFLOW_UID: ${AIRFLOW_UID}
    AIRFLOW_GID: ${AIRFLOW_GID}
    TZ: ${TZ}
    PYTHONPATH: /opt/airflow
  volumes:
    - ./platform/orchestration/airflow/dags:/opt/airflow/dags
    - ./platform/orchestration/airflow/logs:/opt/airflow/logs
    - ./platform/orchestration/airflow/plugins:/opt/airflow/plugins
    - ./platform/orchestration/airflow/config:/opt/airflow/config
    - ./platform/quality/great_expectations:/opt/great_expectations
    - ./platform/orchestration/airflow/include:/opt/airflow/include
    - ./platform/orchestration/airflow/runtime-requirements.txt:/requirements/requirements.txt
    - ./platform/featurestore/feast_repo:/opt/airflow/feast_repo
    - ./platform/ml:/opt/airflow/platform/ml
    - ./storage/data:/opt/airflow/storage/data
    - bentoml_store:/home/airflow/bentoml
  user: "${AIRFLOW_UID}:${AIRFLOW_GID}"
  depends_on:
    postgres:
      condition: service_healthy
    redis:
      condition: service_started

services:
  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command: -c "\
      mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins && \
      pip install --no-cache-dir -r /opt/airflow/config/requirements.txt && \
      airflow db migrate && \
      airflow users create \
        --username admin \
        --firstname Admin \
        --lastname User \
        --role Admin \
        --email admin@example.com \
        --password admin && \
      airflow db check"
    profiles:
      - bootstrap

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    profiles:
      - core
    ports:
      - "8793:8793"
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $(hostname)"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 60s

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    profiles:
      - core
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health"]
      interval: 30s
      timeout: 30s
      retries: 5
      start_period: 60s

  airflow-triggerer:
    <<: *airflow-common
    command: triggerer
    profiles:
      - core

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    profiles:
      - core
    environment:
      <<: *airflow-common-env
      AIRFLOW__CELERY__WORKER_CONCURRENCY: 4

  airflow-flower:
    <<: *airflow-common
    command: celery flower
    profiles:
      - core
    ports:
      - "5555:5555"

  postgres:
    image: postgres:15
    profiles:
      - core
    env_file:
      - .env
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
      TZ: ${TZ}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./platform/analytics/postgres/seeds:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    profiles:
      - core
    command: redis-server --save 20 1 --loglevel warning
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  clickhouse:
    image: clickhouse/clickhouse-server:23.8
    profiles:
      - core
      - analytics
    env_file:
      - .env
    environment:
      CLICKHOUSE_DB: ${CLICKHOUSE_DB}
      CLICKHOUSE_USER: ${CLICKHOUSE_USER}
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      TZ: ${TZ}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./platform/analytics/clickhouse/config:/etc/clickhouse-server/config.d
      - ./platform/analytics/clickhouse/init:/docker-entrypoint-initdb.d
    ports:
      - "8123:8123"
      - "9009:9009"
      - "9363:9363"

  minio:
    image: minio/minio:latest
    profiles:
      - core
      - ingestion
      - ml
    env_file:
      - .env
    command: server /data --console-address ":${MINIO_CONSOLE_PORT}"
    ports:
      - "${MINIO_API_PORT}:9000"
      - "${MINIO_CONSOLE_PORT}:9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 5

  infisical-db:
    image: postgres:15
    profiles:
      - core
    environment:
      POSTGRES_DB: infisical
      POSTGRES_USER: infisical
      POSTGRES_PASSWORD: infisical
    volumes:
      - infisical_pg:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U infisical"]
      interval: 10s
      timeout: 5s
      retries: 5

  infisical-redis:
    image: redis:7
    profiles:
      - core
    command: redis-server --save 20 1 --loglevel warning
    volumes:
      - infisical_redis:/data

  infisical:
    image: infisical/infisical:latest
    profiles:
      - core
    env_file:
      - .env
    environment:
      NODE_ENV: production
      ENCRYPTION_KEY: ${INFISICAL_ENCRYPTION_KEY}
      AUTH_SECRET: ${INFISICAL_AUTH_SECRET}
      DATABASE_URL: postgresql://infisical:infisical@infisical-db:5432/infisical
      DATABASE_HOST: infisical-db
      DATABASE_PORT: 5432
      DATABASE_USERNAME: infisical
      DATABASE_PASSWORD: infisical
      DATABASE_NAME: infisical
      DB_HOST: infisical-db
      DB_PORT: 5432
      DB_USER: infisical
      DB_PASSWORD: infisical
      DB_NAME: infisical
      REDIS_URL: redis://infisical-redis:6379
      PORT: 8080
      SITE_URL: http://localhost:8082
    ports:
      - "8082:8080"
    depends_on:
      infisical-db:
        condition: service_healthy
      infisical-redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5

  airbyte-db:
    image: postgres:15
    profiles:
      - ingestion
    environment:
      POSTGRES_DB: ${AIRBYTE_DATABASE_DB}
      POSTGRES_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      POSTGRES_USER: ${AIRBYTE_DATABASE_USER}
    volumes:
      - airbyte_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${AIRBYTE_DATABASE_USER}"]
      interval: 10s
      timeout: 5s
      retries: 10

  airbyte-temporal:
    image: airbyte/temporal:${AIRBYTE_VERSION}
    profiles:
      - ingestion
    env_file:
      - .env
    environment:
      DB: postgresql
      DB_PORT: ${AIRBYTE_DATABASE_PORT}
      POSTGRES_USER: ${AIRBYTE_DATABASE_USER}
      POSTGRES_PWD: ${AIRBYTE_DATABASE_PASSWORD}
      POSTGRES_SEEDS: airbyte-db
      DYNAMIC_CONFIG_FILE_PATH: config/dynamicconfig/development.yaml
      LOG_LEVEL: ${AIRBYTE_LOG_LEVEL}
    volumes:
      - ./platform/ingestion/airbyte/temporal/dynamicconfig:/etc/temporal/config/dynamicconfig
    depends_on:
      airbyte-db:
        condition: service_healthy

  airbyte-temporal-ui:
    image: temporalio/ui:2.42.1
    profiles:
      - ingestion
    environment:
      - TEMPORAL_ADDRESS=airbyte-temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:8000
    depends_on:
      - airbyte-temporal

  airbyte-bootloader:
    image: airbyte/bootloader:${AIRBYTE_VERSION}
    profiles:
      - ingestion
    env_file:
      - .env
    environment:
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      LOCAL_CONNECTOR_CATALOG_PATH: ${LOCAL_CONNECTOR_CATALOG_PATH}
      LOG_LEVEL: ${AIRBYTE_LOG_LEVEL}
    depends_on:
      airbyte-db:
        condition: service_healthy
    restart: "no"

  airbyte-server:
    image: airbyte/server:${AIRBYTE_VERSION}
    profiles:
      - ingestion
    env_file:
      - .env
    environment:
      AIRBYTE_ROLE: server
      AIRBYTE_WORKSPACE_ROOT: ${AIRBYTE_WORKSPACE_ROOT}
      AIRBYTE_CONFIG_ROOT: ${AIRBYTE_CONFIG_ROOT}
      AIRBYTE_LOGS_ROOT: ${AIRBYTE_LOGS_ROOT}
      AIRBYTE_TEMPORAL_HOST: airbyte-temporal:7233
      LOCAL_ROOT: ${LOCAL_ROOT}
      LOCAL_DOCKER_MOUNT: ${LOCAL_DOCKER_MOUNT}
      WORKSPACE_ROOT: ${WORKSPACE_ROOT}
      CONFIG_ROOT: ${CONFIG_ROOT}
      DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      CONFIG_DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      CONFIG_DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      CONFIG_DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      JOB_DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      JOB_DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      JOB_DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      RUN_DATABASE_MIGRATION_ON_STARTUP: "true"
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      LOG_LEVEL: ${AIRBYTE_LOG_LEVEL}
      WORKER_ENVIRONMENT: ${WORKER_ENVIRONMENT}
      CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: ${CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION}
      JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: ${JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION}
      LOCAL_CONNECTOR_CATALOG_PATH: ${LOCAL_CONNECTOR_CATALOG_PATH}
    ports:
      - "8001:8001"
    volumes:
      - airbyte_data:/data
      - airbyte_workspace:/workspace
    depends_on:
      airbyte-db:
        condition: service_healthy
      airbyte-temporal:
        condition: service_started
      airbyte-bootloader:
        condition: service_completed_successfully

  airbyte-worker:
    image: airbyte/worker:${AIRBYTE_VERSION}
    profiles:
      - ingestion
    env_file:
      - .env
    environment:
      AIRBYTE_ROLE: worker
      AIRBYTE_WORKSPACE_ROOT: ${AIRBYTE_WORKSPACE_ROOT}
      AIRBYTE_CONFIG_ROOT: ${AIRBYTE_CONFIG_ROOT}
      AIRBYTE_LOGS_ROOT: ${AIRBYTE_LOGS_ROOT}
      AIRBYTE_TEMPORAL_HOST: airbyte-temporal:7233
      LOCAL_ROOT: ${LOCAL_ROOT}
      LOCAL_DOCKER_MOUNT: ${LOCAL_DOCKER_MOUNT}
      WORKSPACE_ROOT: ${WORKSPACE_ROOT}
      CONFIG_ROOT: ${CONFIG_ROOT}
      DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      CONFIG_DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      CONFIG_DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      CONFIG_DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      JOB_DATABASE_URL: jdbc:postgresql://${AIRBYTE_DATABASE_HOST}:${AIRBYTE_DATABASE_PORT}/${AIRBYTE_DATABASE_DB}
      JOB_DATABASE_USER: ${AIRBYTE_DATABASE_USER}
      JOB_DATABASE_PASSWORD: ${AIRBYTE_DATABASE_PASSWORD}
      AIRBYTE_VERSION: ${AIRBYTE_VERSION}
      LOG_LEVEL: ${AIRBYTE_LOG_LEVEL}
      WORKER_ENVIRONMENT: ${WORKER_ENVIRONMENT}
      CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: ${CONFIGS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION}
      JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION: ${JOBS_DATABASE_MINIMUM_FLYWAY_MIGRATION_VERSION}
      LOCAL_CONNECTOR_CATALOG_PATH: ${LOCAL_CONNECTOR_CATALOG_PATH}
    depends_on:
      airbyte-server:
        condition: service_started
      airbyte-temporal:
        condition: service_started
      airbyte-db:
        condition: service_healthy
      airbyte-bootloader:
        condition: service_completed_successfully
    volumes:
      - airbyte_workspace:/workspace
      - airbyte_data:/data

  airbyte-webapp:
    image: airbyte/webapp:${AIRBYTE_VERSION}
    profiles:
      - ingestion
    env_file:
      - .env
    environment:
      INTERNAL_API_HOST: ${INTERNAL_API_HOST}
      INTERNAL_API_URL: ${INTERNAL_API_URL}
      WEBAPP_URL: ${WEBAPP_URL}
    ports:
      - "8000:80"
    depends_on:
      airbyte-server:
        condition: service_started
      airbyte-bootloader:
        condition: service_completed_successfully

  spark-master:
    image: bitnami/spark:3.5.1
    profiles:
      - ingestion
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    ports:
      - "${SPARK_MASTER_RPC_PORT}:7077"
      - "${SPARK_MASTER_WEB_PORT}:8080"

  spark-worker:
    image: bitnami/spark:3.5.1
    profiles:
      - ingestion
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 1G
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "${SPARK_WORKER_WEB_PORT}:8081"
    depends_on:
      - spark-master

  flink-jobmanager:
    image: flink:1.17-scala_2.12-java11
    profiles:
      - ingestion
    command: jobmanager
    ports:
      - "${FLINK_REST_PORT}:8081"
      - "${FLINK_RPC_PORT}:6123"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.heap.size: 512m
        rest.port: 8081
        rest.address: 0.0.0.0
        rest.bind-address: 0.0.0.0

  flink-taskmanager:
    image: flink:1.17-scala_2.12-java11
    profiles:
      - ingestion
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 2
        taskmanager.heap.size: 512m
    depends_on:
      - flink-jobmanager

  openmetadata-postgres:
    image: postgres:15
    profiles:
      - catalog
    environment:
      POSTGRES_DB: openmetadata
      POSTGRES_USER: ${OPENMETADATA_DB_USER}
      POSTGRES_PASSWORD: ${OPENMETADATA_DB_PASSWORD}
    volumes:
      - openmetadata_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${OPENMETADATA_DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  openmetadata-elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.4
    profiles:
      - catalog
    environment:
      discovery.type: single-node
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
    volumes:
      - openmetadata_es:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 15

  openmetadata-server:
    image: openmetadata/server:1.4.1
    profiles:
      - catalog
    env_file:
      - .env
    environment:
      OPENMETADATA_DB_USER: ${OPENMETADATA_DB_USER}
      OPENMETADATA_DB_PASSWORD: ${OPENMETADATA_DB_PASSWORD}
      OPENMETADATA_POSTGRES_HOST: openmetadata-postgres
      OPENMETADATA_POSTGRES_PORT: 5432
      OPENMETADATA_CLUSTER_NAME: "local"
      OPENMETADATA_ELASTICSEARCH_HOST: openmetadata-elasticsearch
      OPENMETADATA_ELASTICSEARCH_PORT: 9200
      SERVER_PORT: ${OPENMETADATA_SERVER_PORT}
      AUTHENTICATION_PROVIDER: no-auth
    ports:
      - "${OPENMETADATA_SERVER_PORT}:8585"
      - "${OPENMETADATA_API_PORT}:8586"
    volumes:
      - ./platform/catalog/openmetadata/config:/openmetadata/config
      - ./platform/catalog/openmetadata/ingestion:/openmetadata/ingestion
    depends_on:
      openmetadata-postgres:
        condition: service_healthy
      openmetadata-elasticsearch:
        condition: service_healthy

  openmetadata-ingestion:
    image: openmetadata/ingestion:1.4.1
    profiles:
      - catalog
    env_file:
      - .env
    volumes:
      - ./platform/catalog/openmetadata/ingestion:/openmetadata/ingestion
    depends_on:
      - openmetadata-server

  liquibase:
    image: liquibase/liquibase:4.25
    working_dir: /workspace/liquibase
    volumes:
      - ./platform/versioning/liquibase:/workspace/liquibase
      - ./platform/analytics/postgres/seeds:/workspace/seeds
    env_file:
      - .env
    profiles:
      - tools


  grafana:
    image: grafana/grafana:10.3.3
    profiles:
      - observability
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_INSTALL_PLUGINS: grafana-clock-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./platform/observability/grafana/dashboards:/var/lib/grafana/dashboards
      - ./platform/observability/grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3000:3000"
    depends_on:
      - prometheus

  prometheus:
    image: prom/prometheus:v2.49.0
    profiles:
      - observability
    volumes:
      - ./platform/observability/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  mlflow-db:
    image: postgres:15
    profiles:
      - ml
    environment:
      POSTGRES_USER: ${MLFLOW_DB_USER}
      POSTGRES_PASSWORD: ${MLFLOW_DB_PASSWORD}
      POSTGRES_DB: ${MLFLOW_BACKEND_DB}
    volumes:
      - mlflow_db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${MLFLOW_DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  mlflow:
    build:
      context: platform/ml/mlflow
      dockerfile: Dockerfile
    profiles:
      - ml
    env_file:
      - .env
    environment:
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
    command: >
      mlflow server
        --backend-store-uri postgresql://${MLFLOW_DB_USER}:${MLFLOW_DB_PASSWORD}@mlflow-db:5432/${MLFLOW_BACKEND_DB}
        --default-artifact-root ${MLFLOW_ARTIFACT_ROOT}
        --host 0.0.0.0
        --port 5000
    ports:
      - "5000:5000"
    depends_on:
      mlflow-db:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:5000')\""]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 20s

  bentoml:
    build:
      context: platform/ml/bento_service
      dockerfile: Dockerfile
    profiles:
      - ml
    env_file:
      - .env
    environment:
      BENTOML_HOME: /home/bento/bentoml
      MLFLOW_TRACKING_URI: ${MLFLOW_INTERNAL_TRACKING_URI}
      MLFLOW_S3_ENDPOINT_URL: ${MLFLOW_S3_ENDPOINT_URL}
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      MLFLOW_MODEL_NAME: ${MLFLOW_MODEL_NAME}
    volumes:
      - bentoml_store:/home/bento/bentoml
    ports:
      - "${BENTOML_PORT}:3001"
    depends_on:
      mlflow:
        condition: service_started

  streamlit:
    build:
      context: platform/apps/streamlit_app
      dockerfile: Dockerfile
    profiles:
      - ml
    env_file:
      - .env
    environment:
      BENTO_ENDPOINT: http://bentoml:3001/predict
    volumes:
      - ./platform/apps/streamlit_app:/app
    ports:
      - "${STREAMLIT_PORT}:8501"
    depends_on:
      bentoml:
        condition: service_started

  metabase:
    image: metabase/metabase:v0.49.10
    profiles:
      - analytics
    env_file:
      - .env
    environment:
      MB_DB_FILE: /metabase-data/metabase.db
      MB_PLUGINS_DIR: /plugins
      MB_EMOJI_IN_LOGS: "true"
    ports:
      - "${METABASE_PORT}:3000"
    depends_on:
      clickhouse:
        condition: service_started
    volumes:
      - metabase_data:/metabase-data
      - ./platform/analytics/metabase/plugins:/plugins

networks:
  default:
    name: ${PROJECT_NETWORK}

volumes:
  postgres_data:
  redis_data:
  clickhouse_data:
  minio_data:
  airbyte_db:
  airbyte_workspace:
  airbyte_data:
  openmetadata_db:
  openmetadata_es:
  grafana_data:
  infisical_pg:
  infisical_redis:
  mlflow_db:
  bentoml_store:
  metabase_data:
